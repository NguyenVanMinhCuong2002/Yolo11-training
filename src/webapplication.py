import streamlit as st
from ultralytics import YOLO
from PIL import Image
import tempfile
import cv2
import os

# Load model YOLO (c√≥ th·ªÉ thay b·∫±ng yolov8n.pt, yolov8s.pt t√πy nhu c·∫ßu)
model = YOLO("yolov11-experiment/exp/weights/best.pt")

st.title("üéØ Object Detection App")
st.write("Upload ·∫£nh ho·∫∑c video ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng v·ªõi YOLOv8")

# Ch·ªçn lo·∫°i input
option = st.radio("Ch·ªçn ki·ªÉu d·ªØ li·ªáu:", ("·∫¢nh", "Video"))

if option == "·∫¢nh":
    uploaded_file = st.file_uploader("Upload m·ªôt ·∫£nh", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)

        # D·ª± ƒëo√°n
        results = model(image)
        res_img = results[0].plot()  # render k·∫øt qu·∫£
        st.image(res_img, caption="K·∫øt qu·∫£ ph√°t hi·ªán", use_container_width=True)

elif option == "Video":
    uploaded_video = st.file_uploader("Upload m·ªôt video", type=["mp4", "avi", "mov"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False) 
        tfile.write(uploaded_video.read())

        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model(frame)
            annotated_frame = results[0].plot()

            stframe.image(annotated_frame, channels="BGR")

        cap.release()
        os.remove(tfile.name)
